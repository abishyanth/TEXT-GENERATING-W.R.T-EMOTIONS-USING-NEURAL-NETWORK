{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XoDuvX-C2Jr5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Activation, Dense, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZFwy_8Y2QqO",
        "outputId": "3752ca5c-fe9c-432a-81de-2085562abbf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
        "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "54MfWsUJ2d0_"
      },
      "outputs": [],
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wQ3d8hpO2xVx"
      },
      "outputs": [],
      "source": [
        "text = text[30000:800000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vyIGLbfk22hx"
      },
      "outputs": [],
      "source": [
        "characters = sorted(set(text))\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X7Em59KE3dU3"
      },
      "outputs": [],
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "sentences = []\n",
        "next_char = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C48p_ku03ozT"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text[i + SEQ_LENGTH])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7yhheLXJ3u3w"
      },
      "outputs": [],
      "source": [
        "bool_array = np.array([True, False, True], dtype=np.bool_)\n",
        "x = np.zeros((len(sentences), SEQ_LENGTH,len(characters)), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences),len(characters)), dtype=np.bool_)\n",
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hUrmEyt96RQg"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,input_shape=(SEQ_LENGTH,len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEXsaHiF5pk0",
        "outputId": "4c3423fd-2c20-4a77-9d85-9280a3805fc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1003/1003 [==============================] - 205s 202ms/step - loss: 2.5907\n",
            "Epoch 2/4\n",
            "1003/1003 [==============================] - 203s 203ms/step - loss: 2.2311\n",
            "Epoch 3/4\n",
            "1003/1003 [==============================] - 203s 202ms/step - loss: 2.1050\n",
            "Epoch 4/4\n",
            "1003/1003 [==============================] - 202s 201ms/step - loss: 2.0139\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c67700e6bc0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(lr=0.01))\n",
        "model.fit(x, y, batch_size=256, epochs=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "epBJ06Al6rZj"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=100):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "J3JQpg0eB5j3"
      },
      "outputs": [],
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WlEFLsBBff-W"
      },
      "outputs": [],
      "source": [
        "def generate_mood_text(mood, length, temperature):\n",
        "\n",
        "  mood_dict = {\n",
        "    \"happy\": [\"joyful\", \"cheerful\", \"optimistic\", \"excited\"],\n",
        "    \"sad\": [\"sorrowful\", \"depressed\", \"melancholy\", \"tearful\"],\n",
        "    \"angry\": [\"furious\", \"enraged\", \"indignant\", \"hostile\"],\n",
        "    \"calm\": [\"peaceful\", \"serene\", \"tranquil\", \"composed\"],\n",
        "  }\n",
        "\n",
        "  mood_words = mood_dict.get(mood.lower(), [])\n",
        "\n",
        "  start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "  generated = ''\n",
        "  sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "  generated += sentence\n",
        "\n",
        "  for i in range(length):\n",
        "    x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "    predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "\n",
        "    filtered_predictions = [index for index, prediction in enumerate(predictions) if index_to_char[index] in mood_words]\n",
        "\n",
        "\n",
        "    if len(filtered_predictions) > 0:\n",
        "      next_index = random.choice(filtered_predictions)\n",
        "    else:\n",
        "      next_index = sample(predictions, temperature)\n",
        "\n",
        "    next_character = index_to_char[next_index]\n",
        "\n",
        "    generated += next_character\n",
        "    sentence = sentence[1:] + next_character\n",
        "\n",
        "  return generated\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUo3eiLJhcXi",
        "outputId": "df21179e-dcae-4670-95e4-03ae865324c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------0.3--------\n",
            "mmands.\n",
            "\n",
            "gloucester:\n",
            "\n",
            "clarence:\n",
            "\n",
            "lady grome the me and the wert the say\n",
            "that she whe heave she werd sear,\n",
            "and the werd the beath the will when,\n",
            "the prave the sore what the wall the king\n",
            "and his the geads.\n",
            "\n",
            "corines:\n",
            "and ho she me the mere the ward the pree.\n",
            "\n",
            "herr comen:\n",
            "the werll the some the beath the with heve\n",
            "the beath me for dears enes\n"
          ]
        }
      ],
      "source": [
        "print(\"----------0.3--------\")\n",
        "print(generate_mood_text(\"love\", 300, 0.3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTAm7B31n3vN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.1.-1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
